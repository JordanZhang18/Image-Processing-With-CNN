# Image Processing With CNN
 Dogs vs. Cats kernels Edition Kaggle.com competition using CNN

 Data preparation, exploration, visualization

 The test and training data were provided by Kaggle as zip files. The train folder contains 25,000 images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains 12,500 images, named according to a numeric id.

 The label was extracted using split function, splitting the file names and take the word before ‘.’- dog or cat.
 The training data were converted to array using cv2 imread and resized to 100*100. I read the colored picture so the data contains 3 channels.
 Because of the size of training data is large, the first 2500 pictures were read as training set, otherwise the training time will be very long.  
 The X and Y of training set were generated by extracting first and second element of each item in the training set array, and reshaped to appropriate sizes. The test data set is similarly extracted and transformed. The Y label was transformed using LabelEncoder and to category.

 To verify that the data was extracted correctly, I run imshow to show the fourth picture in X train and it shows a cute cat.

 Review research design and modeling methods

 Coevolutionary Neural Network is used to build the model. The first model trained contains 8 layers of conv2D layers, separated by four Maxpooling layers.
 The number of filters starts with 32 then 64, 96, 96. All conv. Layers uses SAME padding and ReLu as activation function.And top three layers are flatten layer, dense layer and a outputlayer with 2 nodes and uses sigmoid function.The training uses 20 epochs and took in total about 40 minutes.
 Second model contain of half number of the conv. Layers, with same number of maxpooling layer. So there are in total 4 conv. layers, and 4 pooling layers and with the same top 3 layers.
 
 The training still uses 20 epochs and becomes much faster because of a shallower network. It took about 10 minutes. I realized through test dataset that the prediction accuracy is not good for both above models and it seems the network overfit the training data. So for the next two models, the layers design are same as model1 and 2 but training process only goes through 10 epochs.
